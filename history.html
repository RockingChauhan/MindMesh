<!DOCTYPE html>
<html lang="en" dir="ltr">

<!-- Mirrored from dlprojectsrms.w3spaces.com/history.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 11 Oct 2022 17:07:49 GMT -->
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>History</title>
  <link rel="stylesheet" href="css/swiper-bundle.min.css">
  <link rel="stylesheet" href="css/style.css">

</head>
<body>

  <header>
    <div class="nav-bar">
      <a href="index.html" class="logo">Deep Learning</a>
      
      <div class="navigation">
        <div class="nav-items">
          <i class="uil uil-times nav-close-btn"></i>
          <a href="index.html"><i class="uil uil-home"></i> Home</a>
          <a href="explore.html"><i class="uil uil-compass"></i> Explore</a>
          <a href="about.html"><i class="uil uil-info-circle"></i> About</a>
          <a href="overview.html"><i class="uil uil-envelope"></i>Overview</a>
          <a href="history.html"><i class="uil uil-document-layout-left"></i> History</a>
          <a href="application.html"><i class="uil uil-envelope"></i>Applications</a>
        </div>
      </div>
      <i class="uil uil-apps nav-menu-btn"></i>
    </div>
  </header>
  <section class="home">
    <div class="swiper bg-slider">
      <div class="swiper-wrapper">
        <div class="swiper-slide">
          <img src="images/dl6.jpg" alt="">
        </div>
      </div>
    </div>
  </section>
  <section class="about section">
    <br>
    <center>
      <h2>History</h2>
    </center>
     <p>The first general, working learning algorithm for supervised, deep, feedforward, multilayer perceptrons was published by Alexey Ivakhnenko and Lapa in 1967.
          A 1971 paper described a deep network with eight layers trained by the group method of data handling.
          Other deep learning working architectures, specifically those built for computer vision, began with the Neocognitron introduced by Kunihiko Fukushima in 1980.</p>

    <p>Deep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). 
        Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved.
         Convolutional neural networks (CNNs) were superseded for ASR by CTC for LSTM, but are more successful in computer vision.</p>
      
    <p>Advances in hardware have driven renewed interest in deep learning. In 2009, Nvidia was involved in what was called the “big bang” of deep learning, “as deep-learning neural networks were trained with Nvidia graphics processing units (GPUs).”
         That year, Andrew Ng determined that GPUs could increase the speed of deep-learning systems by about 100 times. 
         In particular, GPUs are well-suited for the matrix/vector computations involved in machine learning.
          GPUs speed up training algorithms by orders of magnitude, reducing running times from weeks to days.
         Further, specialized hardware and algorithm optimizations can be used for efficient processing of deep learning models.</p>
         <left>
         <img src="images/history.jpg" class="center" alt="Evolution of Deep Learning">
         </left>
  </section>
  <div class="footer"> 
    Developed and designed by Sudhanshu Chauhan  
  </div>
</body>

<!-- Mirrored from dlprojectsrms.w3spaces.com/history.html by HTTrack Website Copier/3.x [XR&CO'2014], Tue, 11 Oct 2022 17:07:50 GMT -->
</html>